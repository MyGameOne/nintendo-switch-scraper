name: Nintendo Switch Scraper

on:
  # æ¯å¤© UTC 0ç‚¹ï¼ˆåŒ—äº¬æ—¶é—´ 8ç‚¹ï¼‰è¿è¡Œ
  schedule:
    - cron: "0 0 * * *"

  push:
    branches:
      - main
      - master

  # å…è®¸æ‰‹åŠ¨è§¦å‘ï¼ˆGitHub Actions é¡µé¢ç‚¹å‡»æŒ‰é’®è¿è¡Œï¼‰
  workflow_dispatch:
    inputs:
      concurrent:
        description: "å¹¶å‘æ•°é‡"
        required: false
        default: "3"
        type: string
      delay_min:
        description: "æœ€å°å»¶è¿Ÿ(ms)"
        required: false
        default: "2000"
        type: string
      delay_max:
        description: "æœ€å¤§å»¶è¿Ÿ(ms)"
        required: false
        default: "5000"
        type: string
      batch_size:
        description: "KV é˜Ÿåˆ—æ‰¹æ¬¡å¤§å°"
        required: false
        default: "50"
        type: string

env:
  # é»˜è®¤é…ç½®
  SCRAPER_CONCURRENT: ${{ github.event.inputs.concurrent || '3' }}
  SCRAPER_DELAY_MIN: ${{ github.event.inputs.delay_min || '2000' }}
  SCRAPER_DELAY_MAX: ${{ github.event.inputs.delay_max || '5000' }}
  SCRAPER_BATCH_SIZE: ${{ github.event.inputs.batch_size || '50' }}
  SCRAPER_HEADLESS: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 10

      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Setup pnpm cache
        uses: actions/cache@v3
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install dependencies
        run: |
          if [ -f "pnpm-lock.yaml" ]; then
            echo "ğŸ“¦ ä½¿ç”¨é”å®šæ–‡ä»¶å®‰è£…ä¾èµ–..."
            pnpm install --frozen-lockfile
          else
            echo "ğŸ“¦ ç”Ÿæˆé”å®šæ–‡ä»¶å¹¶å®‰è£…ä¾èµ–..."
            pnpm install
          fi

      - name: Install Playwright browsers
        run: pnpm exec playwright install chromium

      - name: Run scraper
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_D1_DATABASE_ID: ${{ secrets.CLOUDFLARE_D1_DATABASE_ID }}
          CLOUDFLARE_KV_GAME_IDS_ID: ${{ secrets.CLOUDFLARE_KV_GAME_IDS_ID }}
        run: |
          echo "ğŸš€ å¼€å§‹è¿è¡Œ KV é˜Ÿåˆ—çˆ¬è™«..."
          echo "âš™ï¸ é…ç½®ä¿¡æ¯:"
          echo "   å¹¶å‘æ•°: $SCRAPER_CONCURRENT"
          echo "   å»¶è¿ŸèŒƒå›´: ${SCRAPER_DELAY_MIN}-${SCRAPER_DELAY_MAX}ms"
          echo "   æ‰¹æ¬¡å¤§å°: $SCRAPER_BATCH_SIZE"
          echo "   æ— å¤´æ¨¡å¼: $SCRAPER_HEADLESS"
          echo ""

          # è¿è¡Œ KV é˜Ÿåˆ—çˆ¬è™«
          pnpm scrape 2>&1 | tee scraper.log

      - name: Generate summary
        if: always()
        run: |
          echo "## ğŸ® Nintendo Switch çˆ¬è™«è¿è¡ŒæŠ¥å‘Š" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f "scraper.log" ]; then
            # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼è®¡ç®—ç»Ÿè®¡æ•°æ®
            SUCCESS_COUNT=$(grep -c "æˆåŠŸå¤„ç†" scraper.log 2>/dev/null || echo "0")
            FAILED_COUNT=$(grep -c "çˆ¬å–å¤±è´¥" scraper.log 2>/dev/null || echo "0")
            
            # ç¡®ä¿å˜é‡æ˜¯æ•°å­—
            SUCCESS_COUNT=${SUCCESS_COUNT:-0}
            FAILED_COUNT=${FAILED_COUNT:-0}
            TOTAL_COUNT=$((SUCCESS_COUNT + FAILED_COUNT))
            
            echo "### ğŸ“Š ç»Ÿè®¡ä¿¡æ¯" >> $GITHUB_STEP_SUMMARY
            echo "- æ€»è®¡: $TOTAL_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- æˆåŠŸ: $SUCCESS_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- å¤±è´¥: $FAILED_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # æ˜¾ç¤ºå¤±è´¥çš„æ¸¸æˆ ID
            if [ "$FAILED_COUNT" -gt 0 ]; then
              echo "### âŒ å¤±è´¥çš„æ¸¸æˆ ID" >> $GITHUB_STEP_SUMMARY
              grep "çˆ¬å–å¤±è´¥" scraper.log 2>/dev/null | head -20 | while read -r line; do
                echo "- $line" >> $GITHUB_STEP_SUMMARY
              done || true
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
            
            # æ˜¾ç¤ºæˆåŠŸå¤„ç†çš„æ¸¸æˆ
            echo "### âœ… æˆåŠŸå¤„ç†çš„æ¸¸æˆ" >> $GITHUB_STEP_SUMMARY
            grep "æˆåŠŸå¤„ç†" scraper.log 2>/dev/null | head -10 | while read -r line; do
              echo "- $line" >> $GITHUB_STEP_SUMMARY
            done || true
            
            if [ "$SUCCESS_COUNT" -gt 10 ]; then
              REMAINING=$((SUCCESS_COUNT - 10))
              echo "- ... è¿˜æœ‰ $REMAINING ä¸ªæ¸¸æˆ" >> $GITHUB_STEP_SUMMARY
            fi
            
            # æ˜¾ç¤ºé˜Ÿåˆ—ç»Ÿè®¡
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ğŸ“‹ é˜Ÿåˆ—çŠ¶æ€" >> $GITHUB_STEP_SUMMARY
            grep -E "(é˜Ÿåˆ—|pending|processing|completed)" scraper.log 2>/dev/null | tail -5 | while read -r line; do
              echo "- $line" >> $GITHUB_STEP_SUMMARY
            done || true
            
          else
            echo "âŒ æœªæ‰¾åˆ°è¿è¡Œæ—¥å¿—" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs-${{ github.run_number }}
          path: |
            scraper.log
            *.log
          retention-days: 30

      - name: Notify on failure
        if: failure()
        run: |
          echo "ğŸš¨ çˆ¬è™«è¿è¡Œå¤±è´¥ï¼è¯·æ£€æŸ¥æ—¥å¿—ã€‚"
          exit 1
