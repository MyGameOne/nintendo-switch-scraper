name: Nintendo Switch Scraper

on:
  # æ¯å¤© UTC 0ç‚¹ï¼ˆåŒ—äº¬æ—¶é—´ 8ç‚¹ï¼‰è¿è¡Œ
  schedule:
    - cron: '0 0 * * *'
  
  # å½“ data/game-ids.json æ–‡ä»¶å˜æ›´æ—¶è§¦å‘
  push:
    paths:
      - 'data/game-ids.json'
    branches:
      - main
      - master
  
  # å…è®¸æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      concurrent:
        description: 'å¹¶å‘æ•°é‡'
        required: false
        default: '3'
        type: string
      delay_min:
        description: 'æœ€å°å»¶è¿Ÿ(ms)'
        required: false
        default: '2000'
        type: string
      delay_max:
        description: 'æœ€å¤§å»¶è¿Ÿ(ms)'
        required: false
        default: '5000'
        type: string

env:
  # é»˜è®¤é…ç½®
  SCRAPER_CONCURRENT: ${{ github.event.inputs.concurrent || '3' }}
  SCRAPER_DELAY_MIN: ${{ github.event.inputs.delay_min || '2000' }}
  SCRAPER_DELAY_MAX: ${{ github.event.inputs.delay_max || '5000' }}
  SCRAPER_HEADLESS: true
  SCRAPER_PARALLEL: true

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 10
      
      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV
      
      - name: Setup pnpm cache
        uses: actions/cache@v3
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-
      
      - name: Install dependencies
        run: |
          if [ -f "pnpm-lock.yaml" ]; then
            echo "ğŸ“¦ ä½¿ç”¨é”å®šæ–‡ä»¶å®‰è£…ä¾èµ–..."
            pnpm install --frozen-lockfile
          else
            echo "ğŸ“¦ ç”Ÿæˆé”å®šæ–‡ä»¶å¹¶å®‰è£…ä¾èµ–..."
            pnpm install
          fi
      
      - name: Validate game-ids.json
        run: pnpm validate
      
      - name: Install Playwright browsers
        run: pnpm exec playwright install chromium
      
      - name: Run scraper
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_D1_DATABASE_ID: ${{ secrets.CLOUDFLARE_D1_DATABASE_ID }}
        run: |
          echo "ğŸš€ å¼€å§‹è¿è¡Œçˆ¬è™«..."
          echo "âš™ï¸ é…ç½®ä¿¡æ¯:"
          echo "   å¹¶å‘æ•°: $SCRAPER_CONCURRENT"
          echo "   å»¶è¿ŸèŒƒå›´: ${SCRAPER_DELAY_MIN}-${SCRAPER_DELAY_MAX}ms"
          echo "   æ— å¤´æ¨¡å¼: $SCRAPER_HEADLESS"
          echo "   å¹¶è¡Œæ¨¡å¼: $SCRAPER_PARALLEL"
          echo ""
          
          # è¿è¡Œçˆ¬è™«å¹¶æ•è·è¾“å‡º
          pnpm scrape 2>&1 | tee scraper.log
      
      - name: Generate summary
        if: always()
        run: |
          echo "## ğŸ® Nintendo Switch çˆ¬è™«è¿è¡ŒæŠ¥å‘Š" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "scraper.log" ]; then
            SUCCESS_COUNT=$(grep -c "âœ… æˆåŠŸå¤„ç†:" scraper.log || echo "0")
            FAILED_COUNT=$(grep -c "âŒ çˆ¬å–å¤±è´¥:" scraper.log || echo "0")
            TOTAL_COUNT=$((SUCCESS_COUNT + FAILED_COUNT))
            
            echo "### ğŸ“Š ç»Ÿè®¡ä¿¡æ¯" >> $GITHUB_STEP_SUMMARY
            echo "- æ€»è®¡: $TOTAL_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- æˆåŠŸ: $SUCCESS_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- å¤±è´¥: $FAILED_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            if [ "$FAILED_COUNT" -gt 0 ]; then
              echo "### âŒ å¤±è´¥çš„æ¸¸æˆ ID" >> $GITHUB_STEP_SUMMARY
              grep "âŒ çˆ¬å–å¤±è´¥:" scraper.log | sed 's/.*çˆ¬å–å¤±è´¥: /- /' >> $GITHUB_STEP_SUMMARY || true
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
            
            echo "### âœ… æˆåŠŸå¤„ç†çš„æ¸¸æˆ" >> $GITHUB_STEP_SUMMARY
            grep "âœ… æˆåŠŸå¤„ç†:" scraper.log | sed 's/.*æˆåŠŸå¤„ç†: /- /' | head -10 >> $GITHUB_STEP_SUMMARY || true
            
            if [ "$SUCCESS_COUNT" -gt 10 ]; then
              echo "- ... è¿˜æœ‰ $((SUCCESS_COUNT - 10)) ä¸ªæ¸¸æˆ" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âŒ æœªæ‰¾åˆ°è¿è¡Œæ—¥å¿—" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs-${{ github.run_number }}
          path: |
            scraper.log
            *.log
          retention-days: 30
      
      - name: Notify on failure
        if: failure()
        run: |
          echo "ğŸš¨ çˆ¬è™«è¿è¡Œå¤±è´¥ï¼è¯·æ£€æŸ¥æ—¥å¿—ã€‚"
          exit 1